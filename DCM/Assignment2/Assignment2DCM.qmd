---
title: "Assignment 2 - Obama & Happiness - Discrete Choice Modelling"
author: "Marc Sparhuber"
format: pdf
toc: true
execute:
  warning: false
  echo: false
header-includes:
      - \usepackage{float}
      - \floatplacement{table}{H}
engine: knitr
---

\newpage

## Data & Descriptives

REWORK HYPOTHESIS - VOTE IN 2012, SURVEY IN 2016

> The following analysis tests the hypothesis that individuals who were more unhappy, were more likely to vote Obama in 2012. This is expected to be the case because of Obama's promises to implement legislature to alleviate strain on individuals with lower socioeconomic status. One such example is the Affordable Care Act. Due to their lower socioeconomic status, these individuals are hypothesized to experience more hardships and be unhappier and therefore be more likely to vote for Obama. To test this hypothesis, a subset of data from the General Social Survey, conducted by the National Opinion Research at the University of Chicago and provided as part of the socviz package in R is used.

> Table 1 displays descriptive statistics for all variables used for modelling, split by having voted Obama or not, as well as the entire sample. It shows number of respondents and percent within its group and variable for categorical variables and extends this by means and SDs for continuous variables. Of the 1693 individuals indlucded in the analyses, 1058 (62.49%) voted for Obama, while the 635 (37.51) did not. It is important to note that this indicates a slightly skewed sample, as Obama received 51.1% of the popular vote in 2012 (SOURCE). As the main indepdendent variable, Happiness is split into the categories 'Not Too Happy', 'Pretty Happy' and, 'Very Happy'. Across the entire sample, more than half of the respondents reported being 'Pretty Happy' (57.71%), 28.94% reported being 'Very Happy', while 13.35% considered themselves 'Not Too Happy'. Relevant to the hypothesis, while only 9.29% of those who did not vote for Obama reported being 'Not Too Happy', 15.78%	of those who voted Obama did.

```{r}
library(tidyverse)
library(socviz)
library(broom)
library(modelr)
library(DescTools)
library(lmtest)
library(kableExtra)
library(knitr)
library(modelsummary)

# get data ready for descriptives and filter out NAs
gss <- gss_sm |> 
  mutate(parent_degree = case_when(
    is.na(madeg) & is.na(padeg) ~ NA,
    madeg %in% c("Bachelor", "Graduate") | padeg %in% c("Bachelor", "Graduate") ~ "1 or more",
    TRUE ~ "0"),
  obama = recode_factor(obama, `1` = "voted Obama", `0` = "didn't vote Obama"),
         combined = as_factor("combined")) |> 
  relocate(parent_degree, .after = madeg) |> 
  drop_na((c("obama", "age", "sex", "happy", "parent_degree")))

# create table
# Needs to be renamed
datasummary((`Happiness` = happy) + (`Bachelor or Graduate degrees of parents` = parent_degree) + (`Sex` = sex) + Heading("Age", nearData = FALSE) * age + Heading("All", nearData = FALSE) * 1 ~ (obama * (Mean + SD + N + Percent(denom = "col"))) + (combined * (Mean + SD + N + Percent())),
                       data = gss,
                       title = "Descriptives split by voting for Obama",
                       notes = c("Comments: General Social Survey data from the socviz R package.")) |>
                       kable_styling(latex_options="scale_down")

# recode obama and parent_degree for modelling
gss$obama <- as_factor(recode(gss$obama, "didn't vote Obama" = 0, "voted Obama" = 1))
gss$parent_degree <- as_factor(recode(gss$parent_degree, "0" = 0, "1 or more" = 1))
```

## Model Estimaton & Odd Ratios

```{r}
# set "Not Too Happy" as reference category
#levels(gss$happy)

gss <- gss |> mutate(happy = fct_relevel(happy, "Not Too Happy"))

# a) only the happiness variable.

happy_lrm <- glm(obama ~ happy, data = gss, 
                       family = "binomial"(link = "logit"))
#nobs(happy_lrm)
#summary(happy_lrm)

# b) same as a), plus the new parental education variable.

happy_education_lrm <- glm(obama ~ happy + parent_degree, data = gss, 
                       family = "binomial"(link = "logit"))
#nobs(happy_education_lrm)
#summary(happy_education_lrm)

# c) same as b), plus sex and age variables.

happy_education_sex_age_lrm <- glm(obama ~ happy + parent_degree + age + sex, data = gss, 
                       family = "binomial"(link = "logit"))
#nobs(happy_education_sex_age_lrm)
#summary(happy_education_sex_age_lrm)

mods <- list(
  "Model 1" = happy_lrm,
  "Model 2" = happy_education_lrm,
  "Model 3" = happy_education_sex_age_lrm)

modelsummary(mods,
             stars = TRUE,
             gof_omit = "F|RMSE",
             title = "Voting for Obama. Logistic probability models",
             notes = list("Source: General Social Survey data from the socviz R package.", 
                          "Comments: The reference cateogory for happy is 'Not Too Happy'."),
             statistic = "conf.int",
             exponentiate = TRUE)
```

```{r}
estimates_third_mod <- tidy(happy_education_sex_age_lrm, exponentiate = TRUE, conf.int = TRUE)

theme_set(theme_light())

estimates_third_mod |> 
  filter(term != "(Intercept)") |>  
  ggplot(aes(term, estimate)) +
  geom_hline(yintercept = 1, color = "red", linetype = "dashed") +
  geom_point() +
  scale_y_continuous(breaks = seq(0, 2, by = .2), limits = c(0, 2)) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high, width = .1))+
  labs(title = "Voting for Obama: Logistic Regression",
       y = "Odds ratios",
       x = "Variables",
       caption = "General Social Survey Data from the socviz R Package.")
```

## Predicted Probabilities

```{r}
#| fig-width: 7

griddy <- expand_grid(sex = "Female",
            age = seq(min(gss$age), max(gss$age)),
            happy = c("Not Too Happy", "Pretty Happy", "Very Happy"),
            parent_degree = "1")

log_pred_mod3 <- augment(happy_education_sex_age_lrm, 
                           type.predict = "response",
                           se_fit = TRUE,
                           newdata = griddy)

log_pred_mod3 |> 
  mutate(lower = .fitted - 1.96 * .se.fit,
          upper = .fitted + 1.96 * .se.fit) |> 
  ggplot(aes(age, .fitted, color = happy, fill = happy)) +
  geom_line() +
  geom_ribbon(aes(ymin = lower,
                  ymax = upper), 
                  alpha = 0.5) +
  scale_x_continuous(breaks = seq(20, 90, by = 10)) +
  labs(title = "Probability of Obama vote for women with at least one college educated parent",
       subtitle = "Estimated from a logistic regression",
       y = "Predicted probability of Obama vote",
       x = "Age",
       color = "Happiness",
       fill = "Happiness",
       caption = "Data from GSS 2016.")
```

## Model Fit

```{r}
#| fig-align: center

# Perform likelihood ratio tests comparing model b to model a,
# and model c to model b. Also calculate Nagelkerke’s pseudo-R2 and the share of observations
# correctly predicted for all three models.
# Present the above fit statistics in a single, well-formatted and labelled table.
# Describe and interpret the results of these model fit comparisons.


lr_mod12 <- lrtest(happy_lrm, happy_education_lrm)
#lr_mod12[2,5]
lr_mod23 <- lrtest(happy_education_lrm, happy_education_sex_age_lrm)
#lr_mod23[2,5]

mod1_nagel <- PseudoR2(happy_lrm, which = "Nagelkerke")
mod2_nagel <- PseudoR2(happy_education_lrm, which = "Nagelkerke")
mod3_nagel <- PseudoR2(happy_education_sex_age_lrm, which = "Nagelkerke")

correct_pred_m1 <- augment(happy_lrm, type.predict = "response") |> mutate(.pred = as.numeric(.fitted > .5))
correct_pred_m2 <- augment(happy_education_lrm, type.predict = "response") |> mutate(.pred = as.numeric(.fitted > .5))
correct_pred_m3 <- augment(happy_education_sex_age_lrm, type.predict = "response") |> mutate(.pred = as.numeric(.fitted > .5))

share_correct_m1 <- mean(correct_pred_m1$obama == correct_pred_m1$.pred, na.rm = TRUE)
share_correct_m2 <- mean(correct_pred_m2$obama == correct_pred_m2$.pred, na.rm = TRUE)
share_correct_m3 <- mean(correct_pred_m3$obama == correct_pred_m3$.pred, na.rm = TRUE)

data_fit <- as.data.frame(tribble(
  ~`Model 1`, ~`Model 2`, ~`Model 3`,
  as.character(round(mod1_nagel,5)), as.character(round(mod2_nagel,5)), as.character(round(mod3_nagel,5)),
  as.character(round(share_correct_m1,5)), as.character(round(share_correct_m2,5)), as.character(round(share_correct_m3,5)),
  NA, as.character(round(lr_mod12[2,5],5)), as.character(round(lr_mod23[2,5],12))))

rownames(data_fit) <- c("Nagelkerke’s pseudo-R2", "Share of correct predictions", "Likelihood Ratio")

kable(data_fit,
      caption = "Voting for Obama: Model fit statistics") |> 
  footnote(footnote_as_chunk = TRUE,
           threeparttable = TRUE, 
           general = "A prediction is considered correct when its probability is greater than 0.5. The Likelihood ratio is always calculated with the model to the left. Data from GSS 2016.")
```

## Conclusion

