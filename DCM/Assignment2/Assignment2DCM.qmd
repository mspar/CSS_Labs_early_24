---
title: "Assignment 2 - Obama & Happiness - Discrete Choice Modelling"
author: "Marc Sparhuber"
format: pdf
toc: true
execute:
  warning: false
  echo: false
header-includes:
      - \usepackage{float}
      - \floatplacement{table}{H}
engine: knitr
---

\newpage

## Data & Descriptives

```{r}
library(tidyverse)
library(socviz)
library(broom)
library(modelr)
library(DescTools)
library(lmtest)
library(kableExtra)
library(knitr)
library(modelsummary)

# get data ready for descriptives and filter out NAs
gss <- gss_sm |> 
  mutate(parent_degree = case_when(
    is.na(madeg) & is.na(padeg) ~ NA,
    madeg %in% c("Bachelor", "Graduate") | padeg %in% c("Bachelor", "Graduate") ~ "1 or more",
    TRUE ~ "0"),
  obama = recode_factor(obama, `1` = "voted Obama", `0` = "didn't vote Obama"),
         combined = as_factor("combined")) |> 
  relocate(parent_degree, .after = madeg) |> 
  drop_na((c("obama", "age", "sex", "happy", "parent_degree")))

# create table
# Needs to be renamed
datasummary((`Happiness` = happy) + (`Bachelor or Graduate degrees of parents` = parent_degree) + (`Sex` = sex) + Heading("Age", nearData = FALSE) * age + Heading("All", nearData = FALSE) * 1 ~ (obama * (Mean + SD + N + Percent(denom = "col"))) + (combined * (Mean + SD + N + Percent())),
                       data = gss,
                       title = "Descriptives split by voting for Obama",
                       notes = c("Comments: General Social Survey data from the socviz R package.")) |>
                       kable_styling(latex_options="scale_down")

# recode obama and parent_degree for modelling
gss$obama <- as_factor(recode(gss$obama, "didn't vote Obama" = 0, "voted Obama" = 1))
gss$parent_degree <- as_factor(recode(gss$parent_degree, "0" = 0, "1 or more" = 1))
```

> The following analysis tests the hypothesis that individuals who were more unhappy in 2016, were more likely to have voted Obama in 2012. This is expected to be the case because in 2016 individuals who had voted Democrat in 2012 were now faced with Donald Trump as their future president, in some cases leading to protests (SOURCE). To test this hypothesis, a subset of data from the General Social Survey, conducted by the National Opinion Research at the University of Chicago and provided as part of the socviz package in R is used.

> Table 1 displays descriptive statistics for all variables used for modelling, split by having voted Obama or not, as well as the entire sample. It shows number of respondents and percent within its group and variable for categorical variables and extends this by means and SDs for continuous variables. Of the 1693 individuals included in the analyses, 1058 (62.49%) voted for Obama, while the 635 (37.51%) did not. It is important to note that this indicates a slightly skewed sample, as Obama received 51.1% of the popular vote in 2012 (SOURCE). As the main independent variable, Happiness is split into the categories 'Not Too Happy', 'Pretty Happy' and, 'Very Happy'. Across the entire sample, more than half of the respondents reported being 'Pretty Happy' (57.71%), 28.94% reported being 'Very Happy', while 13.35% considered themselves 'Not Too Happy'. Relevant to the hypothesis, while only 9.29% of those who did not vote for Obama reported being 'Not Too Happy', 15.78%	of those who voted Obama did. While the responses for being 'Pretty Happy' were similar across respondents who had voted Obama or not - 58.79% and 55.91%, respectively - noticeably fewer of the Obama voters considered themselves 'Very Happy' (25.43%) than the others (34.80%).

> Further categorical variables describing the sample include whether the respondent had at least one parent with a higher education degree, sex, and age. Interestingly, there seems to be no connection between having voted Obama and higher education, with 75% of this sample having no college educated parent and this percentage not varying across having voted Obama or not. Looking at the sex variable, although 56.88% of respondents were female, voting seemingly split along gender lines with women outweighing men among Obama voters with 60.30% and men being more represented among those who did not vote for Obama with 48.82%. Regarding the age of respondents, the sample mean is 54 years. This varies only slightly across the two conditions, with Obama voters being slightly younger average (52) than non-Obama voters (56). The standard deviation stays at at around 16 in all conditions.

## Model Estimaton & Odd Ratios

```{r}
# set "Not Too Happy" as reference category
#levels(gss$happy)

gss <- gss |> mutate(happy = fct_relevel(happy, "Not Too Happy"))

# a) only the happiness variable.

happy_lrm <- glm(obama ~ happy, data = gss, 
                       family = "binomial"(link = "logit"))
#nobs(happy_lrm)
#summary(happy_lrm)

# b) same as a), plus the new parental education variable.

happy_education_lrm <- glm(obama ~ happy + parent_degree, data = gss, 
                       family = "binomial"(link = "logit"))
#nobs(happy_education_lrm)
#summary(happy_education_lrm)

# c) same as b), plus sex and age variables.

happy_education_sex_age_lrm <- glm(obama ~ happy + parent_degree + age + sex, data = gss, 
                       family = "binomial"(link = "logit"))
#nobs(happy_education_sex_age_lrm)
#summary(happy_education_sex_age_lrm)

mods <- list(
  "Model 1" = happy_lrm,
  "Model 2" = happy_education_lrm,
  "Model 3" = happy_education_sex_age_lrm)

modelsummary(mods,
             stars = TRUE,
             gof_omit = "F|RMSE",
             title = "Voting for Obama. Logistic probability models",
             notes = list("Source: General Social Survey data from the socviz R package.", 
                          "Comments: The reference cateogory for happy is 'Not Too Happy'."),
             statistic = "conf.int",
             exponentiate = TRUE)
```

> Table 2 shows the results of three logistic probability models. Each model contains the full sample of 1693 observations and presents the coefficients as odds ratios with corresponding confidence intervals in square brackets.

```{r}
estimates_third_mod <- tidy(happy_education_sex_age_lrm, exponentiate = TRUE, conf.int = TRUE)

estimates_third_mod[2,1] <- "Very Happy"
estimates_third_mod[3,1] <- "Pretty Happy"
estimates_third_mod[4,1] <- "At least one college educated parent"
estimates_third_mod[5,1] <- "Age"
estimates_third_mod[6,1] <- "Female"

theme_set(theme_light())

estimates_third_mod |> 
  filter(term != "(Intercept)") |>  
  ggplot(aes(term, estimate)) +
  geom_hline(yintercept = 1, color = "red", linetype = "dashed") +
  geom_point() +
  scale_y_continuous(breaks = seq(0, 2, by = .2), limits = c(0, 2)) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high, width = .1)) +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
  labs(title = "Voting for Obama: Logistic Regression",
       y = "Odds ratios",
       x = "Variables",
       caption = "General Social Survey Data from the socviz R Package.",
       tag = "Figure 1")
```


## Predicted Probabilities

```{r}
#| fig-width: 7.5

griddy <- expand_grid(sex = "Female",
            age = seq(min(gss$age), max(gss$age)),
            happy = c("Not Too Happy", "Pretty Happy", "Very Happy"),
            parent_degree = "1")

log_pred_mod3 <- augment(happy_education_sex_age_lrm, 
                           type.predict = "response",
                           se_fit = TRUE,
                           newdata = griddy)

log_pred_mod3 |> 
  mutate(lower = .fitted - 1.96 * .se.fit,
          upper = .fitted + 1.96 * .se.fit) |> 
  ggplot(aes(age, .fitted, color = happy, fill = happy)) +
  geom_line() +
  geom_ribbon(aes(ymin = lower,
                  ymax = upper), 
                  alpha = 0.5) +
  scale_x_continuous(breaks = seq(20, 90, by = 10)) +
  labs(title = "Probability of Obama vote for women with at least one college educated parent",
       subtitle = "Estimated from a logistic regression",
       y = "Predicted probability of Obama vote",
       x = "Age",
       color = "Happiness",
       fill = "Happiness",
       caption = "Data from GSS 2016.",
       tag = "Figure 2")
```

## Model Fit

```{r}
#| fig-align: center

# Perform likelihood ratio tests comparing model b to model a,
# and model c to model b. Also calculate Nagelkerke’s pseudo-R2 and the share of observations
# correctly predicted for all three models.
# Present the above fit statistics in a single, well-formatted and labelled table.
# Describe and interpret the results of these model fit comparisons.


lr_mod12 <- lrtest(happy_lrm, happy_education_lrm)
#lr_mod12[2,5]
lr_mod23 <- lrtest(happy_education_lrm, happy_education_sex_age_lrm)
#lr_mod23[2,5]

mod1_nagel <- PseudoR2(happy_lrm, which = "Nagelkerke")
mod2_nagel <- PseudoR2(happy_education_lrm, which = "Nagelkerke")
mod3_nagel <- PseudoR2(happy_education_sex_age_lrm, which = "Nagelkerke")

correct_pred_m1 <- augment(happy_lrm, type.predict = "response") |> mutate(.pred = as.numeric(.fitted > .5))
correct_pred_m2 <- augment(happy_education_lrm, type.predict = "response") |> mutate(.pred = as.numeric(.fitted > .5))
correct_pred_m3 <- augment(happy_education_sex_age_lrm, type.predict = "response") |> mutate(.pred = as.numeric(.fitted > .5))

share_correct_m1 <- mean(correct_pred_m1$obama == correct_pred_m1$.pred, na.rm = TRUE)
share_correct_m2 <- mean(correct_pred_m2$obama == correct_pred_m2$.pred, na.rm = TRUE)
share_correct_m3 <- mean(correct_pred_m3$obama == correct_pred_m3$.pred, na.rm = TRUE)

data_fit <- as.data.frame(tribble(
  ~`Model 1`, ~`Model 2`, ~`Model 3`,
  as.character(round(mod1_nagel,5)), as.character(round(mod2_nagel,5)), as.character(round(mod3_nagel,5)),
  as.character(round(share_correct_m1,5)), as.character(round(share_correct_m2,5)), as.character(round(share_correct_m3,5)),
  NA, as.character(round(lr_mod12[2,5],5)), as.character(round(lr_mod23[2,5],12))))

rownames(data_fit) <- c("Nagelkerke’s pseudo-R2", "Share of correct predictions", "Likelihood Ratio")

kable(data_fit,
      caption = "Voting for Obama: Model fit statistics") |> 
  footnote(footnote_as_chunk = TRUE,
           threeparttable = TRUE, 
           general = "A prediction is considered correct when its probability is greater than 0.5. The Likelihood ratio is always calculated with the model to the left. Data from GSS 2016.")
```

## Conclusion

